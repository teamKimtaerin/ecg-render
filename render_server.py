"""
GPU Render Server for MotionText Video Processing
EC2 GPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” ë Œë”ë§ ì„œë²„
"""

import sys
from pathlib import Path
import logging
import os
import warnings
from typing import Dict, Any, Optional
from datetime import datetime
import asyncio
import uuid

from dotenv import load_dotenv
load_dotenv()

warnings.filterwarnings("ignore", category=UserWarning)

from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import uvicorn

from modules.queue import RenderQueue, RenderJob
from modules.worker import RenderWorker
from src.logger import get_logger

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="GPU Render Server",
    description="GPU ê¸°ë°˜ MotionText ë¹„ë””ì˜¤ ë Œë”ë§ ì„œë²„",
    version="1.0.0",
)

# í™˜ê²½ ì„¤ì •
S3_BUCKET = os.getenv("S3_BUCKET", "ecg-rendered-videos")
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")
BACKEND_CALLBACK_URL = os.getenv("BACKEND_CALLBACK_URL", "")
MAX_CONCURRENT_JOBS = int(os.getenv("MAX_CONCURRENT_JOBS", "3"))
TEMP_DIR = os.getenv("TEMP_DIR", "/tmp/render")

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)

# ì „ì—­ ê°ì²´
render_queue: Optional[RenderQueue] = None
render_workers: list[RenderWorker] = []
worker_tasks: list[asyncio.Task] = []


# ========== Pydantic Models ==========

class RenderRequest(BaseModel):
    """ë Œë”ë§ ìš”ì²­ ëª¨ë¸"""
    job_id: str
    video_url: str
    scenario: Dict[str, Any]  # MotionText ì‹œë‚˜ë¦¬ì˜¤
    options: Dict[str, Any] = {
        "width": 1920,
        "height": 1080,
        "fps": 30,
        "quality": 90,
        "format": "mp4"
    }
    callback_url: str


class RenderResponse(BaseModel):
    """ë Œë”ë§ ì‘ë‹µ ëª¨ë¸"""
    status: str
    job_id: str
    message: str


class JobStatus(BaseModel):
    """ì‘ì—… ìƒíƒœ ëª¨ë¸"""
    job_id: str
    status: str
    progress: int
    message: Optional[str] = None
    download_url: Optional[str] = None
    error_message: Optional[str] = None


# ========== Startup/Shutdown Events ==========

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    global render_queue, render_workers, worker_tasks

    logger.info("GPU ë Œë”ë§ ì„œë²„ ì´ˆê¸°í™” ì¤‘...")

    # Redis í ì´ˆê¸°í™”
    render_queue = RenderQueue(redis_url=REDIS_URL)

    # ì›Œì»¤ ì„¤ì •
    worker_config = {
        "s3_bucket": S3_BUCKET,
        "temp_dir": TEMP_DIR,
    }

    # ì›Œì»¤ ìƒì„± ë° ì‹œì‘
    for i in range(MAX_CONCURRENT_JOBS):
        worker = RenderWorker(render_queue, worker_config)
        render_workers.append(worker)

        # ë¹„ë™ê¸° íƒœìŠ¤í¬ë¡œ ì›Œì»¤ ì‹œì‘
        task = asyncio.create_task(worker.start())
        worker_tasks.append(task)

        logger.info(f"ë Œë”ë§ ì›Œì»¤ {i+1} ì‹œì‘ë¨")

    # GPU ìƒíƒœ í™•ì¸
    check_gpu_status()

    logger.info(f"âœ… GPU ë Œë”ë§ ì„œë²„ ì¤€ë¹„ ì™„ë£Œ (ì›Œì»¤: {MAX_CONCURRENT_JOBS}ê°œ)")


@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    global render_workers, worker_tasks

    logger.info("GPU ë Œë”ë§ ì„œë²„ ì¢…ë£Œ ì¤‘...")

    # ëª¨ë“  ì›Œì»¤ ì •ì§€
    for worker in render_workers:
        await worker.stop()

    # ì›Œì»¤ íƒœìŠ¤í¬ ì·¨ì†Œ
    for task in worker_tasks:
        task.cancel()
        try:
            await task
        except asyncio.CancelledError:
            pass

    logger.info("âœ… GPU ë Œë”ë§ ì„œë²„ ì¢…ë£Œ ì™„ë£Œ")


# ========== Helper Functions ==========

def check_gpu_status():
    """GPU ìƒíƒœ í™•ì¸"""
    try:
        import torch

        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            logger.info(f"ğŸ® GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_count}ê°œ")

            for i in range(gpu_count):
                props = torch.cuda.get_device_properties(i)
                logger.info(f"  GPU {i}: {props.name}")
                logger.info(f"    - ë©”ëª¨ë¦¬: {props.total_memory / 1024**3:.1f} GB")
                logger.info(f"    - CUDA ì½”ì–´: {props.multi_processor_count}")
        else:
            logger.warning("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

    except ImportError:
        logger.warning("PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # FFmpeg GPU ì¸ì½”ë”© í™•ì¸
    try:
        import subprocess
        result = subprocess.run(
            ['ffmpeg', '-hide_banner', '-encoders'],
            capture_output=True,
            text=True,
            timeout=5
        )

        if 'h264_nvenc' in result.stdout:
            logger.info("âœ… NVENC GPU ì¸ì½”ë”© ì‚¬ìš© ê°€ëŠ¥")
        else:
            logger.warning("âš ï¸ NVENC GPU ì¸ì½”ë”©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"FFmpeg í™•ì¸ ì‹¤íŒ¨: {e}")


# ========== API Endpoints ==========

@app.post("/api/render/process", response_model=RenderResponse)
async def process_render_job(request: RenderRequest):
    """ë Œë”ë§ ì‘ì—… ìˆ˜ì‹  ë° íì— ì¶”ê°€"""
    try:
        logger.info(f"ë Œë”ë§ ìš”ì²­ ìˆ˜ì‹  - job_id: {request.job_id}")

        # RenderJob ìƒì„±
        job = RenderJob(
            job_id=request.job_id,
            video_url=request.video_url,
            scenario=request.scenario,
            options=request.options,
            callback_url=request.callback_url
        )

        # íì— ì¶”ê°€
        await render_queue.add_job(job)

        logger.info(f"ì‘ì—…ì´ íì— ì¶”ê°€ë¨ - job_id: {request.job_id}")

        return RenderResponse(
            status="accepted",
            job_id=request.job_id,
            message="Job queued for processing"
        )

    except Exception as e:
        logger.error(f"ì‘ì—… ì¶”ê°€ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to queue job: {str(e)}"
        )


@app.post("/api/render/{job_id}/cancel")
async def cancel_render_job(job_id: str):
    """ë Œë”ë§ ì‘ì—… ì·¨ì†Œ"""
    try:
        success = render_queue.cancel_job(job_id)

        if success:
            logger.info(f"ì‘ì—… ì·¨ì†Œë¨ - job_id: {job_id}")
            return {"success": True, "message": "Job cancelled successfully"}
        else:
            return {"success": False, "message": "Job not found or already completed"}

    except Exception as e:
        logger.error(f"ì‘ì—… ì·¨ì†Œ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to cancel job: {str(e)}"
        )


@app.get("/api/render/{job_id}/status", response_model=JobStatus)
async def get_job_status(job_id: str):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    try:
        job = render_queue.get_job(job_id)

        if not job:
            raise HTTPException(
                status_code=404,
                detail="Job not found"
            )

        return JobStatus(
            job_id=job.job_id,
            status=job.status,
            progress=job.progress,
            message=f"Job is {job.status}",
            error_message=job.error_message
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get job status: {str(e)}"
        )


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        queue_status = render_queue.get_queue_status() if render_queue else {}

        # GPU ë©”ëª¨ë¦¬ ì²´í¬
        gpu_info = {}
        try:
            import torch
            if torch.cuda.is_available():
                for i in range(torch.cuda.device_count()):
                    allocated = torch.cuda.memory_allocated(i) / 1024**3
                    reserved = torch.cuda.memory_reserved(i) / 1024**3
                    gpu_info[f"gpu_{i}"] = {
                        "allocated_gb": round(allocated, 2),
                        "reserved_gb": round(reserved, 2)
                    }
        except:
            pass

        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "queue": queue_status,
            "gpu": gpu_info,
            "workers": len(render_workers)
        }

    except Exception as e:
        logger.error(f"í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }


@app.get("/api/render/queue/status")
async def get_queue_status():
    """í ìƒíƒœ ì¡°íšŒ"""
    try:
        status = render_queue.get_queue_status()
        return status

    except Exception as e:
        logger.error(f"í ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get queue status: {str(e)}"
        )


@app.post("/api/render/queue/clear")
async def clear_queue():
    """í ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ìš©)"""
    try:
        if os.getenv("ENVIRONMENT") != "production":
            render_queue.clear_queue()
            return {"success": True, "message": "Queue cleared"}
        else:
            raise HTTPException(
                status_code=403,
                detail="Queue clearing is disabled in production"
            )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to clear queue: {str(e)}"
        )


# ========== Main ==========

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="GPU Render Server")
    parser.add_argument("--host", default="0.0.0.0", help="ë°”ì¸ë“œ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--port", type=int, default=8090, help="ë°”ì¸ë“œ í¬íŠ¸")
    parser.add_argument("--workers", type=int, default=1, help="ìœ ë¹„ì½˜ ì›Œì»¤ ìˆ˜")
    parser.add_argument(
        "--log-level", default="info",
        choices=["debug", "info", "warning", "error"]
    )

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=getattr(logging, args.log_level.upper()),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    logger.info("ğŸš€ GPU ë Œë”ë§ ì„œë²„ ì‹œì‘")
    logger.info(f"   í˜¸ìŠ¤íŠ¸: {args.host}:{args.port}")
    logger.info(f"   ìœ ë¹„ì½˜ ì›Œì»¤: {args.workers}")
    logger.info(f"   ë Œë”ë§ ì›Œì»¤: {MAX_CONCURRENT_JOBS}")
    logger.info(f"   Redis: {REDIS_URL}")
    logger.info(f"   S3 ë²„í‚·: {S3_BUCKET}")
    logger.info(f"   ì½œë°± URL: {BACKEND_CALLBACK_URL if BACKEND_CALLBACK_URL else 'Not configured'}")

    # FastAPI ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "render_server:app",
        host=args.host,
        port=args.port,
        workers=args.workers,
        access_log=True,
        log_level=args.log_level,
        reload=False
    )